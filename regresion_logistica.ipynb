{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>amenities</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate.1</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>0</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Essentials\", \"Heating\", \"TV with standard ca...</td>\n",
       "      <td>f</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100</td>\n",
       "      <td>Private room in home</td>\n",
       "      <td>Private room</td>\n",
       "      <td>[\"Fire extinguisher\", \"Outdoor furniture\", \"Sh...</td>\n",
       "      <td>t</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>100</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Fire extinguisher\", \"Outdoor furniture\", \"Ro...</td>\n",
       "      <td>t</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.92</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100</td>\n",
       "      <td>Private room in home</td>\n",
       "      <td>Private room</td>\n",
       "      <td>[\"Fire extinguisher\", \"Bed linens\", \"Indoor fi...</td>\n",
       "      <td>t</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>94</td>\n",
       "      <td>Entire rental unit</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>[\"Essentials\", \"Microwave\", \"Heating\", \"Stove\"...</td>\n",
       "      <td>t</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  host_response_time  host_acceptance_rate         property_type  \\\n",
       "0           0  within a few hours                     0    Entire rental unit   \n",
       "1           1  within a few hours                   100  Private room in home   \n",
       "2           2      within an hour                   100    Entire rental unit   \n",
       "3           3  within a few hours                   100  Private room in home   \n",
       "4           4  within a few hours                    94    Entire rental unit   \n",
       "\n",
       "         room_type                                          amenities  \\\n",
       "0  Entire home/apt  [\"Essentials\", \"Heating\", \"TV with standard ca...   \n",
       "1     Private room  [\"Fire extinguisher\", \"Outdoor furniture\", \"Sh...   \n",
       "2  Entire home/apt  [\"Fire extinguisher\", \"Outdoor furniture\", \"Ro...   \n",
       "3     Private room  [\"Fire extinguisher\", \"Bed linens\", \"Indoor fi...   \n",
       "4  Entire home/apt  [\"Essentials\", \"Microwave\", \"Heating\", \"Stove\"...   \n",
       "\n",
       "  host_is_superhost  host_response_rate  host_acceptance_rate.1  \\\n",
       "0                 f               100.0                    89.6   \n",
       "1                 t               100.0                   100.0   \n",
       "2                 t               100.0                   100.0   \n",
       "3                 t               100.0                   100.0   \n",
       "4                 t               100.0                    94.0   \n",
       "\n",
       "   host_listings_count  ...  review_scores_cleanliness  review_scores_checkin  \\\n",
       "0                  1.0  ...                       4.92                   4.97   \n",
       "1                  3.0  ...                       4.92                   4.97   \n",
       "2                  1.0  ...                       4.86                   4.97   \n",
       "3                  3.0  ...                       4.81                   4.92   \n",
       "4                  2.0  ...                       4.91                   4.95   \n",
       "\n",
       "   review_scores_communication  review_scores_location  review_scores_value  \\\n",
       "0                         4.97                    4.87                 4.90   \n",
       "1                         4.97                    4.87                 4.90   \n",
       "2                         4.94                    4.92                 4.72   \n",
       "3                         5.00                    4.81                 4.86   \n",
       "4                         5.00                    4.98                 4.93   \n",
       "\n",
       "   calculated_host_listings_count  \\\n",
       "0                             1.0   \n",
       "1                             2.0   \n",
       "2                             1.0   \n",
       "3                             2.0   \n",
       "4                             1.0   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                          1.0   \n",
       "1                                          0.0   \n",
       "2                                          1.0   \n",
       "3                                          0.0   \n",
       "4                                          1.0   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  \\\n",
       "0                                           0.0   \n",
       "1                                           2.0   \n",
       "2                                           0.0   \n",
       "3                                           2.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  \n",
       "0                                          0.0               0.94  \n",
       "1                                          0.0               0.94  \n",
       "2                                          0.0               3.03  \n",
       "3                                          0.0               0.36  \n",
       "4                                          0.0               0.62  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargar archivo csv desde seaborn\n",
    "#Convertir en dataframe\n",
    "df_sydney= pd.read_csv(\"Sydney.csv\")\n",
    "df_sydney.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sydney.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sydney.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creación de Categorias a partir de clases***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16.0, 792.0]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['price'].max()\n",
    "Min=df_sydney['price'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15., 404., 793.])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(15, 793, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las categorías \n",
    "categorias= [\"cheap\", \"expensive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_numerico=df_sydney[\"price\"]\n",
    "df_sydney.insert(0,\"price_numerico\",price_numerico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['price']=pd.cut(x= df_sydney['price'], bins=intervalos, labels= categorias )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        cheap\n",
       "1        cheap\n",
       "2        cheap\n",
       "3        cheap\n",
       "4    expensive\n",
       "Name: price, dtype: category\n",
       "Categories (2, object): ['cheap' < 'expensive']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sydney['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sydney[\"price\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4098   12]\n",
      " [ 550    5]]\n",
      "Precisión del modelo:\n",
      "0.8816695352839932\n",
      "Precisión del modelo:\n",
      "0.29411764705882354\n",
      "Exactitud del modelo:\n",
      "0.8795284030010718\n",
      "Sensibilidad del modelo:\n",
      "0.997080291970803\n",
      "Sensibilidad del modelo:\n",
      "0.009009009009009009\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df_sydney[['accommodates']]\n",
    "Var_Dep= df_sydney['price']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"cheap\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"expensive\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"cheap\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"expensive\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['host_total_listings_count'].max()\n",
    "Min=df_sydney['host_total_listings_count'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites\n",
    "\n",
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(-1, 466, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['host_total_listings_count']\n",
    "df_sydney.insert(0,\"host_total_listings_count_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['host_total_listings_count']=pd.cut(x= df_sydney['host_total_listings_count'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['host_total_listings_count'].head()\n",
    "\n",
    "df_sydney[\"host_total_listings_count\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4556    0]\n",
      " [ 109    0]]\n",
      "Precisión del modelo:\n",
      "0.9766345123258307\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9766345123258307\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df_sydney[['accommodates']]\n",
    "Var_Dep= df_sydney['host_total_listings_count']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 3***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['reviews_per_month'].max()\n",
    "Min=df_sydney['reviews_per_month'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites\n",
    "\n",
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(0, 5.79, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['reviews_per_month']\n",
    "df_sydney.insert(0,\"reviews_per_month_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['reviews_per_month']=pd.cut(x= df_sydney['reviews_per_month'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['reviews_per_month'].head()\n",
    "\n",
    "df_sydney[\"reviews_per_month\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4051    0]\n",
      " [ 614    0]]\n",
      "Precisión del modelo:\n",
      "0.8683815648445874\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.8683815648445874\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df_sydney[['host_response_rate']]\n",
    "Var_Dep= df_sydney['reviews_per_month']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 4***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barn', 'Boat', 'Camper/RV', 'Campsite', 'Casa particular', 'Dome',\n",
       "       'Earthen home', 'Entire bungalow', 'Entire cabin', 'Entire condo',\n",
       "       'Entire cottage', 'Entire guest suite', 'Entire guesthouse',\n",
       "       'Entire home', 'Entire home/apt', 'Entire loft', 'Entire place',\n",
       "       'Entire rental unit', 'Entire serviced apartment',\n",
       "       'Entire townhouse', 'Entire vacation home', 'Entire villa',\n",
       "       'Farm stay', 'Holiday park', 'Houseboat', 'Hut', 'Island',\n",
       "       'Private room', 'Private room in bed and breakfast',\n",
       "       'Private room in bungalow', 'Private room in cabin',\n",
       "       'Private room in camper/rv', 'Private room in casa particular',\n",
       "       'Private room in chalet', 'Private room in condo',\n",
       "       'Private room in cottage', 'Private room in earthen home',\n",
       "       'Private room in guest suite', 'Private room in guesthouse',\n",
       "       'Private room in home', 'Private room in hostel',\n",
       "       'Private room in loft', 'Private room in minsu',\n",
       "       'Private room in rental unit', 'Private room in resort',\n",
       "       'Private room in serviced apartment', 'Private room in tiny home',\n",
       "       'Private room in townhouse', 'Private room in treehouse',\n",
       "       'Private room in vacation home', 'Private room in villa',\n",
       "       'Private room in yurt', 'Room in aparthotel',\n",
       "       'Room in boutique hotel', 'Room in hotel',\n",
       "       'Room in serviced apartment', 'Shared room',\n",
       "       'Shared room in bed and breakfast',\n",
       "       'Shared room in boutique hotel', 'Shared room in condo',\n",
       "       'Shared room in guesthouse', 'Shared room in home',\n",
       "       'Shared room in hostel', 'Shared room in rental unit',\n",
       "       'Shared room in townhouse', 'Shared room in villa', 'Tent',\n",
       "       'Tiny home', 'Train', 'Treehouse'], dtype=object)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"property_type\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"property_type\"]=df_sydney[\"property_type\"].replace(['Barn', 'Boat', 'Camper/RV', 'Campsite', 'Casa particular', 'Dome',\n",
    "       'Earthen home', 'Entire bungalow', 'Entire cabin', 'Entire condo',\n",
    "       'Entire cottage', 'Entire guest suite', 'Entire guesthouse',\n",
    "       'Entire home', 'Entire home/apt', 'Entire loft', 'Entire place',\n",
    "       'Entire rental unit', 'Entire serviced apartment',\n",
    "       'Entire townhouse', 'Entire vacation home', 'Entire villa',\n",
    "       'Farm stay', 'Holiday park', 'Houseboat', 'Hut', 'Island',\n",
    "       'Private room', 'Private room in bed and breakfast',\n",
    "       'Private room in bungalow', 'Private room in cabin',\n",
    "       'Private room in camper/rv', 'Private room in casa particular',\n",
    "       'Private room in chalet', 'Private room in condo',\n",
    "       'Private room in cottage', 'Private room in earthen home',\n",
    "       'Private room in guest suite', 'Private room in guesthouse',\n",
    "       'Private room in home'],\"grupo1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"property_type\"]=df_sydney[\"property_type\"].replace(['Private room in hostel',\n",
    "       'Private room in loft', 'Private room in minsu',\n",
    "       'Private room in rental unit', 'Private room in resort',\n",
    "       'Private room in serviced apartment', 'Private room in tiny home',\n",
    "       'Private room in townhouse', 'Private room in treehouse',\n",
    "       'Private room in vacation home', 'Private room in villa',\n",
    "       'Private room in yurt', 'Room in aparthotel',\n",
    "       'Room in boutique hotel', 'Room in hotel',\n",
    "       'Room in serviced apartment', 'Shared room',\n",
    "       'Shared room in bed and breakfast',\n",
    "       'Shared room in boutique hotel', 'Shared room in condo',\n",
    "       'Shared room in guesthouse', 'Shared room in home',\n",
    "       'Shared room in hostel', 'Shared room in rental unit',\n",
    "       'Shared room in townhouse', 'Shared room in villa', 'Tent',\n",
    "       'Tiny home', 'Train', 'Treehouse'],\"grupo2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4218    0]\n",
      " [ 447    0]]\n",
      "Precisión del modelo:\n",
      "0.9041800643086817\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9041800643086817\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['host_response_rate']]\n",
    "Var_Dep = df_sydney['property_type']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 5***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a few days or more', 'within a day', 'within a few hours',\n",
       "       'within an hour'], dtype=object)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"host_response_time\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"host_response_time\"]=df_sydney[\"host_response_time\"].replace(['a few days or more', 'within a day'],\"grupo1\")\n",
    "df_sydney[\"host_response_time\"]=df_sydney[\"host_response_time\"].replace(['within a few hours','within an hour'],\"grupo2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4199    0]\n",
      " [ 466    0]]\n",
      "Precisión del modelo:\n",
      "0.9001071811361201\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9001071811361201\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['price_numerico']]\n",
    "Var_Dep = df_sydney['host_response_time']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 6***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f', 't'], dtype=object)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"host_is_superhost\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[3215    0]\n",
      " [1450    0]]\n",
      "Precisión del modelo:\n",
      "0.6891747052518756\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.6891747052518756\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['review_scores_communication']]\n",
    "Var_Dep = df_sydney['host_is_superhost']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 7***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
       "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
       "         34,   35,   36,   37,   38,   40,   42,   43,   44,   45,   46,\n",
       "         47,   48,   49,   50,   51,   52,   55,   56,   57,   58,   59,\n",
       "         60,   61,   62,   63,   65,   68,   70,   71,   73,   74,   75,\n",
       "         80,   84,   85,   87,   88,   89,   90,   91,   92,   93,   95,\n",
       "         97,   98,   99,  100,  110,  112,  113,  119,  120,  123,  124,\n",
       "        125,  130,  138,  140,  150,  152,  154,  155,  156,  160,  165,\n",
       "        167,  170,  175,  176,  177,  178,  180,  181,  182,  183,  185,\n",
       "        186,  188,  190,  194,  200,  201,  206,  210,  218,  220,  240,\n",
       "        250,  255,  260,  265,  270,  280,  299,  300,  305,  309,  316,\n",
       "        320,  325,  330,  334,  335,  336,  350,  352,  354,  355,  356,\n",
       "        358,  360,  362,  363,  364,  365,  366,  367,  368,  369,  390,\n",
       "        395,  400,  415,  465,  500,  555,  600,  672,  700,  720,  725,\n",
       "        729,  730,  750,  800,  999, 1000, 1024, 1095, 1100, 1108, 1111,\n",
       "       1114, 1120, 1122, 1123, 1124, 1125, 1126, 1162])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"maximum_nights\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['maximum_nights'].max()\n",
    "Min=df_sydney['maximum_nights'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites\n",
    "\n",
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(0, 1163, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['maximum_nights']\n",
    "df_sydney.insert(0,\"maximum_nights_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['maximum_nights']=pd.cut(x= df_sydney['maximum_nights'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['maximum_nights'].head()\n",
    "\n",
    "df_sydney[\"maximum_nights\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[3062  237]\n",
      " [ 963  403]]\n",
      "Precisión del modelo:\n",
      "0.7607453416149068\n",
      "Precisión del modelo:\n",
      "0.6296875\n",
      "Exactitud del modelo:\n",
      "0.7427652733118971\n",
      "Sensibilidad del modelo:\n",
      "0.9281600484995454\n",
      "Sensibilidad del modelo:\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['minimum_nights']]\n",
    "Var_Dep = df_sydney['maximum_nights']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 8***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['bathrooms'].max()\n",
    "Min=df_sydney['bathrooms'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites\n",
    "\n",
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(-1, 4, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['bathrooms']\n",
    "df_sydney.insert(0,\"bathrooms_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['bathrooms']=pd.cut(x= df_sydney['bathrooms'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['bathrooms'].head()\n",
    "\n",
    "df_sydney[\"bathrooms\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[2919  324]\n",
      " [ 679  743]]\n",
      "Precisión del modelo:\n",
      "0.811284046692607\n",
      "Precisión del modelo:\n",
      "0.6963448922211809\n",
      "Exactitud del modelo:\n",
      "0.784994640943194\n",
      "Sensibilidad del modelo:\n",
      "0.9000925069380203\n",
      "Sensibilidad del modelo:\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['bedrooms']]\n",
    "Var_Dep = df_sydney['bathrooms']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 9***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms_numeric', 'maximum_nights_numeric',\n",
       "       'reviews_per_month_numeric', 'host_total_listings_count_numeric',\n",
       "       'price_numerico', 'Unnamed: 0', 'host_response_time',\n",
       "       'host_acceptance_rate', 'property_type', 'room_type', 'amenities',\n",
       "       'host_is_superhost', 'host_response_rate', 'host_acceptance_rate.1',\n",
       "       'host_listings_count', 'host_total_listings_count', 'latitude',\n",
       "       'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'price',\n",
       "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
       "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
       "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
       "       'maximum_nights_avg_ntm', 'availability_30', 'availability_60',\n",
       "       'availability_90', 'availability_365', 'number_of_reviews',\n",
       "       'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
       "       'review_scores_rating', 'review_scores_accuracy',\n",
       "       'review_scores_cleanliness', 'review_scores_checkin',\n",
       "       'review_scores_communication', 'review_scores_location',\n",
       "       'review_scores_value', 'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sydney.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Entire home/apt', 'Hotel room', 'Private room', 'Shared room'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"room_type\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"room_type\"]=df_sydney[\"room_type\"].replace(['Hotel room', 'Entire home/apt'],\"grupo1\")\n",
    "df_sydney[\"room_type\"]=df_sydney[\"room_type\"].replace(['Shared room',\"Private room\"],\"grupo2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grupo1', 'grupo2'], dtype=object)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"room_type\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4640    0]\n",
      " [  25    0]]\n",
      "Precisión del modelo:\n",
      "0.9946409431939979\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9946409431939979\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['price_numerico']]\n",
    "Var_Dep = df_sydney['room_type']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 10***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['review_scores_location'].max()\n",
    "Min=df_sydney['review_scores_location'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites\n",
    "\n",
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(3.94, 5.1, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['review_scores_location']\n",
    "df_sydney.insert(0,\"review_scores_location_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['review_scores_location']=pd.cut(x= df_sydney['review_scores_location'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['review_scores_location'].head()\n",
    "\n",
    "df_sydney[\"review_scores_location\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[   0  434]\n",
      " [   0 4231]]\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Precisión del modelo:\n",
      "0.9069667738478028\n",
      "Exactitud del modelo:\n",
      "0.9069667738478028\n",
      "Sensibilidad del modelo:\n",
      "0.0\n",
      "Sensibilidad del modelo:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['availability_30']]\n",
    "Var_Dep = df_sydney['review_scores_location']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
