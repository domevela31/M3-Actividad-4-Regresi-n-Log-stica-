{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as special\n",
    "from scipy.optimize import curve_fit\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>...</th>\n",
       "      <th>room_type</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>amenities</th>\n",
       "      <th>calendar_updated</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>calendar_last_scraped</th>\n",
       "      <th>first_review</th>\n",
       "      <th>last_review</th>\n",
       "      <th>license</th>\n",
       "      <th>instant_bookable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.42063</td>\n",
       "      <td>-99.16586</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>[\"40 inch HDTV with Amazon Prime Video, Netfli...</td>\n",
       "      <td>nulos</td>\n",
       "      <td>t</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2013-03-30</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>nulos</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.38283</td>\n",
       "      <td>-99.20000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>[\"Hot water\", \"Washer\", \"Bed linens\", \"Wifi\", ...</td>\n",
       "      <td>nulos</td>\n",
       "      <td>t</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>2013-03-30</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>nulos</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.41162</td>\n",
       "      <td>-99.17794</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1314.4</td>\n",
       "      <td>...</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>5.5 baths</td>\n",
       "      <td>[\"Wifi\", \"Coffee maker: Nespresso\", \"Host gree...</td>\n",
       "      <td>nulos</td>\n",
       "      <td>t</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2011-11-09</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>nulos</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.43956</td>\n",
       "      <td>-99.17263</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>[\"Wifi\", \"Host greets you\", \"Coffee maker\", \"S...</td>\n",
       "      <td>nulos</td>\n",
       "      <td>t</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>nulos</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.41152</td>\n",
       "      <td>-99.16857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1 bath</td>\n",
       "      <td>[\"Wifi\", \"Coffee maker\", \"Sound system\", \"Clot...</td>\n",
       "      <td>nulos</td>\n",
       "      <td>t</td>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>2024-05-05</td>\n",
       "      <td>nulos</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  host_listings_count  host_total_listings_count  latitude  \\\n",
       "0           0                  3.0                        6.0  19.42063   \n",
       "1           1                  1.0                        1.0  19.38283   \n",
       "2           2                 17.0                       17.0  19.41162   \n",
       "3           3                  1.0                        4.0  19.43956   \n",
       "4           4                  3.0                        4.0  19.41152   \n",
       "\n",
       "   longitude  accommodates  bathrooms  bedrooms  beds   price  ...  \\\n",
       "0  -99.16586           2.0        1.0       1.0   2.0  1652.0  ...   \n",
       "1  -99.20000           2.0        1.0       1.0   1.0  3663.0  ...   \n",
       "2  -99.17794           3.1        1.4       5.0   1.8  1314.4  ...   \n",
       "3  -99.17263           4.0        1.0       2.0   3.0   814.0  ...   \n",
       "4  -99.16857           4.0        1.0       2.0   2.0  1923.0  ...   \n",
       "\n",
       "         room_type  bathrooms_text  \\\n",
       "0  Entire home/apt          1 bath   \n",
       "1  Entire home/apt          1 bath   \n",
       "2  Entire home/apt       5.5 baths   \n",
       "3  Entire home/apt          1 bath   \n",
       "4  Entire home/apt          1 bath   \n",
       "\n",
       "                                           amenities  calendar_updated  \\\n",
       "0  [\"40 inch HDTV with Amazon Prime Video, Netfli...             nulos   \n",
       "1  [\"Hot water\", \"Washer\", \"Bed linens\", \"Wifi\", ...             nulos   \n",
       "2  [\"Wifi\", \"Coffee maker: Nespresso\", \"Host gree...             nulos   \n",
       "3  [\"Wifi\", \"Host greets you\", \"Coffee maker\", \"S...             nulos   \n",
       "4  [\"Wifi\", \"Coffee maker\", \"Sound system\", \"Clot...             nulos   \n",
       "\n",
       "   has_availability  calendar_last_scraped  first_review  last_review  \\\n",
       "0                 t             2024-06-28    2013-03-30   2024-04-17   \n",
       "1                 t             2024-06-27    2013-03-30   2024-04-17   \n",
       "2                 t             2024-06-28    2011-11-09   2023-03-26   \n",
       "3                 t             2024-06-28    2013-05-16   2024-05-21   \n",
       "4                 t             2024-06-28    2011-11-17   2024-05-05   \n",
       "\n",
       "   license  instant_bookable  \n",
       "0    nulos                 f  \n",
       "1    nulos                 f  \n",
       "2    nulos                 f  \n",
       "3    nulos                 t  \n",
       "4    nulos                 f  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargar archivo csv desde seaborn\n",
    "#Convertir en dataframe\n",
    "df_sydney= pd.read_csv(\"mexico_limpio.csv\")\n",
    "df_sydney.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   0\n",
       "host_listings_count          0\n",
       "host_total_listings_count    0\n",
       "latitude                     0\n",
       "longitude                    0\n",
       "                            ..\n",
       "calendar_last_scraped        0\n",
       "first_review                 0\n",
       "last_review                  0\n",
       "license                      0\n",
       "instant_bookable             0\n",
       "Length: 112, dtype: int64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sydney.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sydney.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Creación de Categorias a partir de clases***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105.0, 13283.0]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['price'].max()\n",
    "Min=df_sydney['price'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  104.,  6694., 13284.])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(104, 13284, 3)\n",
    "intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las categorías \n",
    "categorias= [\"cheap\", \"expensive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_numerico=df_sydney[\"price\"]\n",
    "df_sydney.insert(0,\"price_numerico\",price_numerico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['price']=pd.cut(x= df_sydney['price'], bins=intervalos, labels= categorias )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    cheap\n",
       "1    cheap\n",
       "2    cheap\n",
       "3    cheap\n",
       "4    cheap\n",
       "Name: price, dtype: category\n",
       "Categories (2, object): ['cheap' < 'expensive']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sydney['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sydney[\"price\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[7866    0]\n",
      " [  95    0]]\n",
      "Precisión del modelo:\n",
      "0.9880668257756563\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9880668257756563\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df_sydney[['accommodates']]\n",
    "Var_Dep= df_sydney['price']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"cheap\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"expensive\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"cheap\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"expensive\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 2***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 442.0]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['host_total_listings_count'].max()\n",
    "Min=df_sydney['host_total_listings_count'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(0, 443, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['host_total_listings_count']\n",
    "df_sydney.insert(0,\"host_total_listings_count_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['host_total_listings_count']=pd.cut(x= df_sydney['host_total_listings_count'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['host_total_listings_count'].head()\n",
    "\n",
    "df_sydney[\"host_total_listings_count\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[7790    0]\n",
      " [ 171    0]]\n",
      "Precisión del modelo:\n",
      "0.9785202863961814\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9785202863961814\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df_sydney[['accommodates']]\n",
    "Var_Dep= df_sydney['host_total_listings_count']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 3***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01, 7.43]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['reviews_per_month'].max()\n",
    "Min=df_sydney['reviews_per_month'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(0, 7.44, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['reviews_per_month']\n",
    "df_sydney.insert(0,\"reviews_per_month_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['reviews_per_month']=pd.cut(x= df_sydney['reviews_per_month'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['reviews_per_month'].head()\n",
    "\n",
    "df_sydney[\"reviews_per_month\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney['host_response_rate'] = df_sydney['host_response_rate'].str.rstrip('%')  # Elimina el %\n",
    "df_sydney['host_response_rate'] = pd.to_numeric(df_sydney['host_response_rate'])   # Convierte a numérico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[7183    0]\n",
      " [ 778    0]]\n",
      "Precisión del modelo:\n",
      "0.9022735837206382\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.9022735837206382\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Declaramos las variables dependientes e independientes para la regresión Logística\n",
    "Vars_Indep= df_sydney[['host_response_rate']]\n",
    "Var_Dep= df_sydney['reviews_per_month']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 4***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Boat', 'Campsite', 'Casa particular', 'Castle', 'Dome',\n",
       "       'Earthen home', 'Entire bungalow', 'Entire cabin', 'Entire chalet',\n",
       "       'Entire condo', 'Entire cottage', 'Entire guest suite',\n",
       "       'Entire guesthouse', 'Entire home', 'Entire home/apt',\n",
       "       'Entire hostel', 'Entire in-law', 'Entire loft', 'Entire place',\n",
       "       'Entire rental unit', 'Entire serviced apartment',\n",
       "       'Entire townhouse', 'Entire vacation home', 'Entire villa',\n",
       "       'Farm stay', 'Holiday park', 'Hut', 'Private room',\n",
       "       'Private room in barn', 'Private room in bed and breakfast',\n",
       "       'Private room in bungalow', 'Private room in cabin',\n",
       "       'Private room in casa particular', 'Private room in castle',\n",
       "       'Private room in chalet', 'Private room in condo',\n",
       "       'Private room in cottage', 'Private room in dome',\n",
       "       'Private room in dorm', 'Private room in earthen home',\n",
       "       'Private room in farm stay', 'Private room in floor',\n",
       "       'Private room in guest suite', 'Private room in guesthouse',\n",
       "       'Private room in home', 'Private room in hostel',\n",
       "       'Private room in houseboat', 'Private room in hut',\n",
       "       'Private room in lighthouse', 'Private room in loft',\n",
       "       'Private room in minsu', 'Private room in nature lodge',\n",
       "       'Private room in pension', 'Private room in rental unit',\n",
       "       'Private room in resort', 'Private room in serviced apartment',\n",
       "       'Private room in shipping container', 'Private room in tent',\n",
       "       'Private room in tiny home', 'Private room in tower',\n",
       "       'Private room in townhouse', 'Private room in vacation home',\n",
       "       'Private room in villa', 'Room in aparthotel',\n",
       "       'Room in bed and breakfast', 'Room in boutique hotel',\n",
       "       'Room in casa particular', 'Room in hostel', 'Room in hotel',\n",
       "       'Room in serviced apartment', 'Shared room',\n",
       "       'Shared room in bed and breakfast',\n",
       "       'Shared room in boutique hotel', 'Shared room in cabin',\n",
       "       'Shared room in casa particular', 'Shared room in condo',\n",
       "       'Shared room in dorm', 'Shared room in guest suite',\n",
       "       'Shared room in guesthouse', 'Shared room in home',\n",
       "       'Shared room in hostel', 'Shared room in hotel',\n",
       "       'Shared room in loft', 'Shared room in rental unit',\n",
       "       'Shared room in serviced apartment', 'Shared room in tent',\n",
       "       'Shared room in tiny home', 'Shared room in townhouse',\n",
       "       'Shared room in vacation home', 'Shipping container', 'Tent',\n",
       "       'Tiny home', 'Tipi'], dtype=object)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"property_type\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"property_type\"]=df_sydney[\"property_type\"].replace(['Boat', 'Campsite', 'Casa particular', 'Castle', 'Dome',\n",
    "       'Earthen home', 'Entire bungalow', 'Entire cabin', 'Entire chalet',\n",
    "       'Entire condo', 'Entire cottage', 'Entire guest suite',\n",
    "       'Entire guesthouse', 'Entire home', 'Entire home/apt',\n",
    "       'Entire hostel', 'Entire in-law', 'Entire loft', 'Entire place',\n",
    "       'Entire rental unit', 'Entire serviced apartment',\n",
    "       'Entire townhouse', 'Entire vacation home', 'Entire villa',\n",
    "       'Farm stay', 'Holiday park', 'Hut', 'Private room',\n",
    "       'Private room in barn', 'Private room in bed and breakfast',\n",
    "       'Private room in bungalow', 'Private room in cabin',\n",
    "       'Private room in casa particular', 'Private room in castle',\n",
    "       'Private room in chalet', 'Private room in condo',\n",
    "       'Private room in cottage', 'Private room in dome',\n",
    "       'Private room in dorm', 'Private room in earthen home',\n",
    "       'Private room in farm stay', 'Private room in floor',\n",
    "       'Private room in guest suite', 'Private room in guesthouse',\n",
    "       'Private room in home', 'Private room in hostel',\n",
    "       'Private room in houseboat', 'Private room in hut',\n",
    "       'Private room in lighthouse', 'Private room in loft',\n",
    "       'Private room in minsu', 'Private room in nature lodge',],\"grupo1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"property_type\"]=df_sydney[\"property_type\"].replace(['Private room in pension', 'Private room in rental unit',\n",
    "       'Private room in resort', 'Private room in serviced apartment',\n",
    "       'Private room in shipping container', 'Private room in tent',\n",
    "       'Private room in tiny home', 'Private room in tower',\n",
    "       'Private room in townhouse', 'Private room in vacation home',\n",
    "       'Private room in villa', 'Room in aparthotel',\n",
    "       'Room in bed and breakfast', 'Room in boutique hotel',\n",
    "       'Room in casa particular', 'Room in hostel', 'Room in hotel',\n",
    "       'Room in serviced apartment', 'Shared room',\n",
    "       'Shared room in bed and breakfast',\n",
    "       'Shared room in boutique hotel', 'Shared room in cabin',\n",
    "       'Shared room in casa particular', 'Shared room in condo',\n",
    "       'Shared room in dorm', 'Shared room in guest suite',\n",
    "       'Shared room in guesthouse', 'Shared room in home',\n",
    "       'Shared room in hostel', 'Shared room in hotel',\n",
    "       'Shared room in loft', 'Shared room in rental unit',\n",
    "       'Shared room in serviced apartment', 'Shared room in tent',\n",
    "       'Shared room in tiny home', 'Shared room in townhouse',\n",
    "       'Shared room in vacation home', 'Shipping container', 'Tent',\n",
    "       'Tiny home', 'Tipi'],\"grupo2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[6589    0]\n",
      " [1372    0]]\n",
      "Precisión del modelo:\n",
      "0.8276598417284261\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.8276598417284261\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['host_response_rate']]\n",
    "Var_Dep = df_sydney['property_type']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 5***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a few days or more', 'within a day', 'within a few hours',\n",
       "       'within an hour'], dtype=object)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"host_response_time\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"host_response_time\"]=df_sydney[\"host_response_time\"].replace(['a few days or more', 'within a day'],\"grupo1\")\n",
    "df_sydney[\"host_response_time\"]=df_sydney[\"host_response_time\"].replace(['within a few hours','within an hour'],\"grupo2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[   0  696]\n",
      " [   0 7265]]\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Precisión del modelo:\n",
      "0.9125737972616506\n",
      "Exactitud del modelo:\n",
      "0.9125737972616506\n",
      "Sensibilidad del modelo:\n",
      "0.0\n",
      "Sensibilidad del modelo:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['price_numerico']]\n",
    "Var_Dep = df_sydney['host_response_time']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 6***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['f', 't'], dtype=object)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"host_is_superhost\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[4732    0]\n",
      " [3229    0]]\n",
      "Precisión del modelo:\n",
      "0.5943976887325713\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Exactitud del modelo:\n",
      "0.5943976887325713\n",
      "Sensibilidad del modelo:\n",
      "1.0\n",
      "Sensibilidad del modelo:\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['review_scores_communication']]\n",
    "Var_Dep = df_sydney['host_is_superhost']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"f\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"t\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 7***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
       "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
       "         34,   35,   36,   37,   38,   39,   40,   42,   43,   44,   45,\n",
       "         46,   48,   49,   50,   52,   55,   56,   57,   58,   59,   60,\n",
       "         61,   62,   63,   64,   65,   69,   70,   71,   75,   80,   82,\n",
       "         83,   84,   85,   88,   89,   90,   91,   92,   93,   94,   95,\n",
       "         96,   99,  100,  102,  112,  114,  115,  118,  119,  120,  122,\n",
       "        125,  130,  135,  137,  140,  141,  150,  152,  160,  168,  170,\n",
       "        174,  175,  179,  180,  181,  182,  183,  184,  185,  186,  187,\n",
       "        188,  190,  193,  197,  199,  200,  210,  212,  220,  221,  238,\n",
       "        240,  250,  254,  255,  260,  265,  280,  290,  300,  301,  309,\n",
       "        320,  322,  325,  330,  340,  345,  350,  354,  355,  356,  358,\n",
       "        359,  360,  362,  363,  364,  365,  366,  367,  369,  370,  380,\n",
       "        385,  388,  390,  398,  400,  415,  430,  452,  466,  500,  515,\n",
       "        520,  540,  567,  600,  666,  700,  710,  720,  725,  729,  730,\n",
       "        750,  800,  900,  999, 1000, 1090, 1095, 1100, 1111, 1120, 1122,\n",
       "       1124, 1125, 1127, 1825])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"maximum_nights\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1825]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['maximum_nights'].max()\n",
    "Min=df_sydney['maximum_nights'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(0, 1826, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['maximum_nights']\n",
    "df_sydney.insert(0,\"maximum_nights_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['maximum_nights']=pd.cut(x= df_sydney['maximum_nights'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['maximum_nights'].head()\n",
    "\n",
    "df_sydney[\"maximum_nights\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[5296   12]\n",
      " [2650    3]]\n",
      "Precisión del modelo:\n",
      "0.6664988673546438\n",
      "Precisión del modelo:\n",
      "0.2\n",
      "Exactitud del modelo:\n",
      "0.6656198969978646\n",
      "Sensibilidad del modelo:\n",
      "0.9977392614920875\n",
      "Sensibilidad del modelo:\n",
      "0.0011307953260459858\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['minimum_nights']]\n",
    "Var_Dep = df_sydney['maximum_nights']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 8***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 4.5]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['bathrooms'].max()\n",
    "Min=df_sydney['bathrooms'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(-1, 4.6, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['bathrooms']\n",
    "df_sydney.insert(0,\"bathrooms_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['bathrooms']=pd.cut(x= df_sydney['bathrooms'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['bathrooms'].head()\n",
    "\n",
    "df_sydney[\"bathrooms\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[5534  170]\n",
      " [1661  596]]\n",
      "Precisión del modelo:\n",
      "0.7691452397498263\n",
      "Precisión del modelo:\n",
      "0.7780678851174935\n",
      "Exactitud del modelo:\n",
      "0.7700037683708076\n",
      "Sensibilidad del modelo:\n",
      "0.9701963534361852\n",
      "Sensibilidad del modelo:\n",
      "0.26406734603455917\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['bedrooms']]\n",
    "Var_Dep = df_sydney['bathrooms']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 9***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms_numeric', 'maximum_nights_numeric',\n",
       "       'reviews_per_month_numeric', 'host_total_listings_count_numeric',\n",
       "       'price_numerico', 'Unnamed: 0', 'host_listings_count',\n",
       "       'host_total_listings_count', 'latitude', 'longitude',\n",
       "       ...\n",
       "       'room_type', 'bathrooms_text', 'amenities', 'calendar_updated',\n",
       "       'has_availability', 'calendar_last_scraped', 'first_review',\n",
       "       'last_review', 'license', 'instant_bookable'],\n",
       "      dtype='object', length=117)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sydney.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Entire home/apt', 'Hotel room', 'Private room', 'Shared room'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"room_type\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney[\"room_type\"]=df_sydney[\"room_type\"].replace(['Hotel room', 'Entire home/apt'],\"grupo1\")\n",
    "df_sydney[\"room_type\"]=df_sydney[\"room_type\"].replace(['Shared room',\"Private room\"],\"grupo2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grupo1', 'grupo2'], dtype=object)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unico = np.unique(df_sydney[\"room_type\"])\n",
    "unico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[5064  148]\n",
      " [1911  838]]\n",
      "Precisión del modelo:\n",
      "0.7260215053763441\n",
      "Precisión del modelo:\n",
      "0.8498985801217038\n",
      "Exactitud del modelo:\n",
      "0.7413641502323829\n",
      "Sensibilidad del modelo:\n",
      "0.9716039907904835\n",
      "Sensibilidad del modelo:\n",
      "0.30483812295380136\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['price_numerico']]\n",
    "Var_Dep = df_sydney['room_type']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo1\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"grupo2\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Modelo 10***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.97, 5.0]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtenemos el limite superior y el límite inferior de la columna objetivo\n",
    "Max=df_sydney['review_scores_location'].max()\n",
    "Min=df_sydney['review_scores_location'].min()\n",
    "Limites= [Min, Max]\n",
    "Limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Categorización de variables\n",
    "#Declaramos 2 intervalos \n",
    "intervalos=np.linspace(3.96, 5.1, 3)\n",
    "intervalos\n",
    "\n",
    "#Creamos las categorías \n",
    "categorias= [\"Alto\", \"Bajo\"]\n",
    "\n",
    "host_total_listings_count_numeric=df_sydney['review_scores_location']\n",
    "df_sydney.insert(0,\"review_scores_location_numeric\", host_total_listings_count_numeric)\n",
    "\n",
    "#Finalmente creamos las categorías en la columna numérica\n",
    "df_sydney['review_scores_location']=pd.cut(x= df_sydney['review_scores_location'], bins=intervalos, labels= categorias )\n",
    "\n",
    "df_sydney['review_scores_location'].head()\n",
    "\n",
    "df_sydney[\"review_scores_location\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[   0  496]\n",
      " [   0 7465]]\n",
      "Precisión del modelo:\n",
      "0.0\n",
      "Precisión del modelo:\n",
      "0.9376962693129004\n",
      "Exactitud del modelo:\n",
      "0.9376962693129004\n",
      "Sensibilidad del modelo:\n",
      "0.0\n",
      "Sensibilidad del modelo:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Declaramos las variables dependientes e independientes para la regresión No lineal\n",
    "Vars_Indep = df_sydney[['availability_30']]\n",
    "Var_Dep = df_sydney['review_scores_location']\n",
    "\n",
    "#Redefinimos las variables \n",
    "X= Vars_Indep\n",
    "y= Var_Dep\n",
    "\n",
    "#Dividimos el conjunto de datos en la parte de entrenamiento y prueba:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state =None)\n",
    "\n",
    "#Se escalan todos los datos\n",
    "escalar = StandardScaler()\n",
    "\n",
    "#Para realizar el escalamiento de las variables “X” tanto de entrenamiento como de prueba, utilizaremos fit_transform\n",
    "X_train = escalar.fit_transform(X_train)\n",
    "X_test = escalar.transform(X_test)\n",
    "\n",
    "#Definimos el algoritmo a utilizar\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algoritmo = LogisticRegression()\n",
    "\n",
    "#Entrenamos el modelo\n",
    "algoritmo.fit(X_train, y_train)\n",
    "\n",
    "#Realizamos una predicción\n",
    "y_pred = algoritmo.predict(X_test) \n",
    "y_pred\n",
    "\n",
    "#Verifico la matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "print('Matriz de Confusión:')\n",
    "print(matriz)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la precisión del modelo\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Precisión del modelo:')\n",
    "print(precision)\n",
    "\n",
    "#Calculo la exactitud del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "exactitud = accuracy_score(y_test, y_pred)\n",
    "print('Exactitud del modelo:')\n",
    "print(exactitud)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Alto\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)\n",
    "\n",
    "#Calculo la sensibilidad del modelo\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sensibilidad = recall_score(y_test, y_pred, average=\"binary\", pos_label=\"Bajo\")\n",
    "print('Sensibilidad del modelo:')\n",
    "print(sensibilidad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
